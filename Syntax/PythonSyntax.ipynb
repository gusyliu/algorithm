{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List 排序\n",
    "### Python List sort()方法\n",
    "+ 描述  \n",
    "sort() 函数用于对原列表进行排序，如果指定参数，则使用比较函数指定的比较函数。\n",
    "\n",
    "+ 语法  \n",
    "sort()方法语法：\n",
    "\n",
    "list.sort(cmp=None, key=None, reverse=False)\n",
    "+ 参数  \n",
    "cmp -- 可选参数, 如果指定了该参数会使用该参数的方法进行排序。\n",
    "key -- 主要是用来进行比较的元素，只有一个参数，具体的函数的参数就是取自于可迭代对象中，指定可迭代对象中的一个元素来进行排序。\n",
    "reverse -- 排序规则，reverse = True 降序， reverse = False 升序（默认）。\n",
    "+ 返回值  \n",
    "该方法没有返回值，但是会对列表的对象进行排序。\n",
    "```\n",
    "#!/usr/bin/python\n",
    "# -*- coding: UTF-8 -*-\n",
    " \n",
    "aList = ['123', 'Google', 'Runoob', 'Taobao', 'Facebook'];\n",
    " \n",
    "aList.sort();\n",
    "print(\"List : \")\n",
    "print(aList)\n",
    "```\n",
    "\n",
    "### sorted() 函数对所有可迭代的对象进行排序操作。\n",
    "\n",
    "sort 与 sorted 区别：\n",
    "\n",
    "sort 是应用在 list 上的方法，sorted 可以对所有可迭代的对象进行排序操作。\n",
    "\n",
    "list 的 sort 方法返回的是对已经存在的列表进行操作，无返回值，而内建函数 sorted 方法返回的是一个新的 list，而不是在原来的基础上进行的操作。\n",
    "\n",
    "+ 语法  \n",
    "sorted 语法：\n",
    "```\n",
    "sorted(iterable, cmp=None, key=None, reverse=False)\n",
    "```\n",
    "+ 参数说明：  \n",
    "\n",
    "iterable -- 可迭代对象。\n",
    "cmp -- 比较的函数，这个具有两个参数，参数的值都是从可迭代对象中取出，此函数必须遵守的规则为，大于则返回1，小于则返回-1，等于则返回0。\n",
    "key -- 主要是用来进行比较的元素，只有一个参数，具体的函数的参数就是取自于可迭代对象中，指定可迭代对象中的一个元素来进行排序。\n",
    "reverse -- 排序规则，reverse = True 降序 ， reverse = False 升序（默认）。\n",
    "+ 返回值  \n",
    "返回重新排序的列表。\n",
    "\n",
    "## List 删除元素\n",
    "\n",
    "在时间效率方面，`pop()`和切片操作`[:-1]`的表现会有所不同，这主要取决于它们的操作方式以及应用的场景。\n",
    "\n",
    "### `pop()`\n",
    "- **时间复杂度**：当使用`pop()`移除列表的最后一个元素时（即`pop()`不带参数），其时间复杂度为O(1)，因为这是对列表末尾的操作。但是，如果你使用`pop(index)`来移除特定索引处的元素（尤其是列表头部，如`pop(0)`），则需要将被移除元素之后的所有元素向前移动一位，这时的时间复杂度是O(n)，其中n是列表的长度。\n",
    "  \n",
    "### `[:-1]` 切片操作\n",
    "- **时间复杂度**：切片操作`[:-1]`创建了一个新的列表，包含了除了原列表最后一个元素外的所有元素。这个操作的时间复杂度是O(n)，因为它需要遍历原列表中除了最后一个元素外的所有元素以构建新列表。\n",
    "  \n",
    "### 总结\n",
    "- 如果你的目标是**从列表中移除最后一个元素，并且你关心的是时间效率，那么直接使用`pop()`是一个更高效的选择**，尤其是在处理大型列表时，因为它的时间复杂度是O(1)。\n",
    "- 如果你需要获取一个不包含最后一个元素的新列表，并且不介意额外的空间开销，则可以使用`[:-1]`切片操作。尽管它的执行时间也依赖于列表的大小（O(n)），但这种方式不会修改原列表，可能更适合那些需要保留原始数据不变的情况。\n",
    "\n",
    "因此，在考虑时间效率时，请根据实际需求选择合适的方法。如果性能是关键考量因素之一，同时只需要移除最后一个元素，那么`pop()`通常是更好的选择。如果需要创建一个新的、略作修改的列表副本而不改变原列表，那么切片操作`[:-1]`则是合适的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch\n",
    "### 矩阵\n",
    "#### 乘法\n",
    "+ 两个张量对应元素相乘，在PyTorch中可以通过torch.mul函数（或*运算符）实现；\n",
    "+ 两个张量矩阵相乘，在PyTorch中可以通过torch.matmul函数实现；\n",
    "\n",
    "#### 转置\n",
    "transpose(dim0, dim1) 是 PyTorch 中的一个方法，用于交换张量的两个指定维度 dim0 和 dim1\n",
    "例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个形状为 (2, 3, 4) 的张量\n",
    "tensor = torch.randn(2, 3, 4)\n",
    "print(tensor.shape)  # 输出: torch.Size([2, 3, 4])\n",
    "\n",
    "# 交换第 1 维和第 2 维\n",
    "transposed_tensor = tensor.transpose(1, 2)\n",
    "print(transposed_tensor.shape)  # 输出: torch.Size([2, 4, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函数\n",
    "#### softmax\n",
    "+ torch.nn.Softmax 是一个类，继承自 torch.nn.Module。当你使用它时，你需要实例化这个类，并且可以将其作为神经网络的一部分包含在模型定义中。\n",
    "+ torch.softmax（或 torch.nn.functional.softmax）是一个函数，可以直接调用，不需要实例化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 使用 torch.nn.Softmax\n",
    "softmax_layer = nn.Softmax(dim=1)\n",
    "input_tensor = torch.randn(2, 3)  # 假设有一个形状为 (2, 3) 的输入张量\n",
    "output = softmax_layer(input_tensor)\n",
    "\n",
    "# 使用 torch.softmax\n",
    "output_functional = torch.softmax(input_tensor, dim=1)\n",
    "\n",
    "print(output)\n",
    "print(output_functional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.size 和 torch.shape\n",
    "在 PyTorch 中，torch.size() 和 torch.shape 都是用于获取张量（tensor）维度信息的方法。虽然它们的功能相似，但在使用上有一些细微的差别。\n",
    "\n",
    "**基本用法**\n",
    "\n",
    "`torch.size()`\n",
    "\n",
    "torch.size() 是一个方法，用于返回张量的维度信息。它可以接受一个可选的参数，用于指定要获取的特定维度。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(a.size()) # 输出: torch.Size([2, 3])\n",
    "print(a.size(0)) # 输出: 2\n",
    "print(a.size(1)) # 输出: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.shape`  \n",
    "torch.shape 是一个属性，用于返回张量的维度信息。它不能接受参数，只能返回整个维度信息。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(a.shape) # 输出: torch.Size([2, 3])\n",
    "print(a.shape[0]) # 输出: 2\n",
    "print(a.shape[1]) # 输出: 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatglm3_6b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
