{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List 排序\n",
    "### Python List sort()方法\n",
    "+ 描述  \n",
    "sort() 函数用于对原列表进行排序，如果指定参数，则使用比较函数指定的比较函数。\n",
    "\n",
    "+ 语法  \n",
    "sort()方法语法：\n",
    "\n",
    "list.sort(cmp=None, key=None, reverse=False)\n",
    "+ 参数  \n",
    "cmp -- 可选参数, 如果指定了该参数会使用该参数的方法进行排序。\n",
    "key -- 主要是用来进行比较的元素，只有一个参数，具体的函数的参数就是取自于可迭代对象中，指定可迭代对象中的一个元素来进行排序。\n",
    "reverse -- 排序规则，reverse = True 降序， reverse = False 升序（默认）。\n",
    "+ 返回值  \n",
    "该方法没有返回值，但是会对列表的对象进行排序。\n",
    "```\n",
    "#!/usr/bin/python\n",
    "# -*- coding: UTF-8 -*-\n",
    " \n",
    "aList = ['123', 'Google', 'Runoob', 'Taobao', 'Facebook'];\n",
    " \n",
    "aList.sort();\n",
    "print(\"List : \")\n",
    "print(aList)\n",
    "```\n",
    "\n",
    "### sorted() 函数对所有可迭代的对象进行排序操作。\n",
    "\n",
    "sort 与 sorted 区别：\n",
    "\n",
    "sort 是应用在 list 上的方法，sorted 可以对所有可迭代的对象进行排序操作。\n",
    "\n",
    "list 的 sort 方法返回的是对已经存在的列表进行操作，无返回值，而内建函数 sorted 方法返回的是一个新的 list，而不是在原来的基础上进行的操作。\n",
    "\n",
    "+ 语法  \n",
    "sorted 语法：\n",
    "```\n",
    "sorted(iterable, cmp=None, key=None, reverse=False)\n",
    "```\n",
    "+ 参数说明：  \n",
    "\n",
    "iterable -- 可迭代对象。\n",
    "cmp -- 比较的函数，这个具有两个参数，参数的值都是从可迭代对象中取出，此函数必须遵守的规则为，大于则返回1，小于则返回-1，等于则返回0。\n",
    "key -- 主要是用来进行比较的元素，只有一个参数，具体的函数的参数就是取自于可迭代对象中，指定可迭代对象中的一个元素来进行排序。\n",
    "reverse -- 排序规则，reverse = True 降序 ， reverse = False 升序（默认）。\n",
    "+ 返回值  \n",
    "返回重新排序的列表。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch\n",
    "### 矩阵\n",
    "#### 乘法\n",
    "+ 两个张量对应元素相乘，在PyTorch中可以通过torch.mul函数（或*运算符）实现；\n",
    "+ 两个张量矩阵相乘，在PyTorch中可以通过torch.matmul函数实现；\n",
    "\n",
    "#### 转置\n",
    "transpose(dim0, dim1) 是 PyTorch 中的一个方法，用于交换张量的两个指定维度 dim0 和 dim1\n",
    "例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个形状为 (2, 3, 4) 的张量\n",
    "tensor = torch.randn(2, 3, 4)\n",
    "print(tensor.shape)  # 输出: torch.Size([2, 3, 4])\n",
    "\n",
    "# 交换第 1 维和第 2 维\n",
    "transposed_tensor = tensor.transpose(1, 2)\n",
    "print(transposed_tensor.shape)  # 输出: torch.Size([2, 4, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函数\n",
    "#### softmax\n",
    "+ torch.nn.Softmax 是一个类，继承自 torch.nn.Module。当你使用它时，你需要实例化这个类，并且可以将其作为神经网络的一部分包含在模型定义中。\n",
    "+ torch.softmax（或 torch.nn.functional.softmax）是一个函数，可以直接调用，不需要实例化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 使用 torch.nn.Softmax\n",
    "softmax_layer = nn.Softmax(dim=1)\n",
    "input_tensor = torch.randn(2, 3)  # 假设有一个形状为 (2, 3) 的输入张量\n",
    "output = softmax_layer(input_tensor)\n",
    "\n",
    "# 使用 torch.softmax\n",
    "output_functional = torch.softmax(input_tensor, dim=1)\n",
    "\n",
    "print(output)\n",
    "print(output_functional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.size 和 torch.shape\n",
    "在 PyTorch 中，torch.size() 和 torch.shape 都是用于获取张量（tensor）维度信息的方法。虽然它们的功能相似，但在使用上有一些细微的差别。\n",
    "\n",
    "**基本用法**\n",
    "\n",
    "`torch.size()`\n",
    "\n",
    "torch.size() 是一个方法，用于返回张量的维度信息。它可以接受一个可选的参数，用于指定要获取的特定维度。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(a.size()) # 输出: torch.Size([2, 3])\n",
    "print(a.size(0)) # 输出: 2\n",
    "print(a.size(1)) # 输出: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.shape`  \n",
    "torch.shape 是一个属性，用于返回张量的维度信息。它不能接受参数，只能返回整个维度信息。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(a.shape) # 输出: torch.Size([2, 3])\n",
    "print(a.shape[0]) # 输出: 2\n",
    "print(a.shape[1]) # 输出: 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatglm3_6b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
